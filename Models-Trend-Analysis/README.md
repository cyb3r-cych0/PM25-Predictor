### ğŸ“Š Trend Analysis â€” PMâ‚‚.â‚… Predictions vs Observations

This folder contains all scripts and tools for **trend computation, significance testing, and visualization** of model predictions versus observed PMâ‚‚.â‚… concentrations.

Trend analysis is a key step in the AirPoll project â€” it quantifies whether predicted PMâ‚‚.â‚… values increase, decrease, or remain stable over time, and compares those trends to the actual measured trends.

---

## ğŸ“˜ Purpose

Once all models have been trained and their predictions saved, the scripts in this folder are used to:
1. Compute **actual vs predicted trends** for each model.
2. Test the **statistical significance** (p-values) of those trends.
3. Create **multi-model trend comparison figures** and diagnostics.

Each script outputs results to a specific directory, making it easy to track, visualize, and report model behaviors.

---

## ğŸ—‚ï¸ Folder structure

Model-trend-Analysis/
â”‚
â”œâ”€â”€ model_trends_actual_vs_pred.py # Computes and plots actual vs predicted & bias trends
â”œâ”€â”€ model_trends_significance.py # Performs significance tests for increasing/decreasing trends
â”œâ”€â”€ model_trend_multi_plots.py # Combines multiple model trends into unified visuals
â”‚
â”œâ”€â”€ actual_vs_pred_trends/ # Output of script 1 â€” per-model PNGs & CSV summary
â”œâ”€â”€ inc-dec_significance_trends/ # Output of script 2 â€” significance results & plots
â”œâ”€â”€ computed_trends_diagnostics/ # Output of script 3 â€” combined multi-model trend plots
â””â”€â”€ README.md # (This file)


---

## âš™ï¸ Script 1 â€” `model_trends_actual_vs_pred.py`

# ğŸ¯ Purpose
Computes and visualizes **actual vs predicted PMâ‚‚.â‚… trends** for each trained model.

# ğŸ” What it does
- Loads predictions and actual PMâ‚‚.â‚… from the `models-training` outputs.  
- Fits linear trends (using `scipy.stats.linregress`) to:
  - **Actual PMâ‚‚.â‚…**  
  - **Predicted PMâ‚‚.â‚…**  
  - **Bias (predicted âˆ’ actual)**  
- Calculates slope (ÂµgÂ·mâ»Â³Â·yrâ»Â¹) and p-value for each series.  
- Saves visual comparisons as dual-panel plots:
  - **Left:** Actual vs predicted with trendlines  
  - **Right:** Bias vs time with its trendline

# â–¶ï¸ Usage
```bash
python model_trends_actual_vs_pred.py
```

# ğŸ“ Output â€” actual_vs_pred_trends/
File	Description
<Model>_actual_vs_pred_trend.png	Trend comparison plots per model
models_actual_vs_pred_trend_summary.csv	Summary table with slope, p-values, and interpretations

# ğŸ§® Example console output
RandomForest â€” Actual trend: -0.2412/yr, p=0.5638 (decreasing, not significant)
GradientBoosting â€” Bias trend: +0.5653/yr, p=0.0361 (increasing, significant)
...
Saved combined summary: models_actual_vs_pred_trend_summary.csv

## âš™ï¸ Script 2 â€” model_trends_significance.py
ğŸ¯ Purpose

Determines whether each variable or model trend is increasing or decreasing and whether that change is statistically significant.

# ğŸ” What it does

Reads output from actual_vs_pred_trends/
Applies trend significance testing (p < 0.05 threshold)
Classifies trends as:
- â€œIncreasing, significantâ€
- â€œIncreasing, not significantâ€
- â€œDecreasing, significantâ€
- â€œDecreasing, not significantâ€

Creates bar or scatter plots visualizing the direction and magnitude of trends across models.

# â–¶ï¸ Usage
python model_trends_significance.py

# ğŸ“ Output â€” inc-dec_significance_trends/
File	Description
<Model>_significance_plot.png	Per-model visual showing trend significance
trend_significance_summary.csv	Summary table with trend direction, slope, and p-values
trend_significance_report.txt	Human-readable interpretation summary

# ğŸ§® Example console output
- RandomForest â€” Decreasing, not significant
- GradientBoosting â€” Increasing, significant
- LSTM â€” Stable, not significant
- Summary saved: trend_significance_summary.csv

## âš™ï¸ Script 3 â€” model_trend_multi_plots.py
ğŸ¯ Purpose

Generates composite multi-model trend diagnostics â€” side-by-side plots comparing slopes and bias trends for all models in a single figure.

# ğŸ” What it does
Loads combined outputs from the previous scripts
- Creates multi-panel plots summarizing:
- Actual vs predicted trends (all models)
- Bias trend magnitudes
- Model performance metrics (RÂ², RMSE, MAE)
- Adds annotations (trend slopes, significance labels)

# â–¶ï¸ Usage
python model_trend_multi_plots.py

# ğŸ“ Output â€” computed_trends_diagnostics/
File	Description
multi_model_trend_comparison.png	Combined slope/bias comparison for all models
trend_diagnostics_table.csv	Consolidated numeric diagnostics
multi_model_summary_plot.png	Compact summary visualization (RÂ² vs bias trend)

## ğŸ“Š Typical example workflow
# Step 1 â€” Compute actual vs predicted trends
python model_trends_actual_vs_pred.py

# Step 2 â€” Assess significance of increasing/decreasing trends
python model_trends_significance.py

# Step 3 â€” Generate multi-model comparison visuals
python model_trends_compute_diag.py

Resulting folders:
- actual_vs_pred_trends/
- inc-dec_significance_trends/
- computed_trends_diagnostics/

Each contains publication-ready CSVs, summaries, and figures.

| Folder                         | Output                                  | Purpose                                       |
| ------------------------------ | --------------------------------------- | --------------------------------------------- |
| `actual_vs_pred_trends/`       | `RandomForest_actual_vs_pred_trend.png` | Shows actual vs predicted vs bias trend       |
| `inc-dec_significance_trends/` | `trend_significance_summary.csv`        | Summarizes increasing/decreasing significance |
| `computed_trends_diagnostics/` | `multi_model_trend_comparison.png`      | Compares all models in one figure             |

# ğŸ§© Integration in the workflow

| Stage                    | Input              | Output                         | Next Step              |
| ------------------------ | ------------------ | ------------------------------ | ---------------------- |
| 1ï¸âƒ£ Trend computation    | Model predictions  | `actual_vs_pred_trends/`       | Significance testing   |
| 2ï¸âƒ£ Significance testing | Trend summary CSVs | `inc-dec_significance_trends/` | Multi-model comparison |
| 3ï¸âƒ£ Multi-model plotting | All summaries      | `computed_trends_diagnostics/` | Reporting / paper      |

# ğŸ§  Interpretation notes

- Slopes are expressed in ÂµgÂ·mâ»Â³Â·yrâ»Â¹
- p-values represent the probability that the slope = 0
- Significance threshold: p < 0.05 (95% confidence)
- Directional interpretation:
- Positive slope â†’ Increasing trend
- Negative slope â†’ Decreasing trend

# ğŸ§¾ Typical outputs summary (example)

| Model            | Actual trend | p(actual) | Pred trend | p(pred) | Bias trend |    p(bias) |       Significance |
| :--------------- | -----------: | --------: | ---------: | ------: | ---------: | ---------: | -----------------: |
| RandomForest     |      âˆ’0.2412 |    0.5638 |    +0.0052 |  0.9838 |    +0.2465 |     0.3256 |    Not significant |
| GradientBoosting |      âˆ’0.2412 |    0.5638 |    +0.3241 |  0.2583 |    +0.5653 | **0.0361** | Bias â†‘ significant |
| Lasso            |      âˆ’0.2412 |    0.5638 |    âˆ’0.1237 |  0.6334 |    +0.1175 |     0.6602 |    Not significant |
| Ridge            |      âˆ’0.2412 |    0.5638 |    âˆ’0.0882 |  0.7328 |    +0.1530 |     0.5697 |    Not significant |
| LSTM             |      âˆ’0.0439 |    0.9195 |    +0.0450 |  0.8868 |    +0.0889 |     0.7369 |    Not significant |
